{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "6a80102b-5617-45b7-e048-3d926d197d13",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12488.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-25 22:30:01--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c09::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M   111MB/s    in 0.8s    \n",
      "\n",
      "2019-05-25 22:30:02 (111 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "('last layer output shape: ', (None, 7, 7, 768))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 我們將使用layers API，選擇layers，並了解我們想要使用哪些，以及我們想要重新training哪些layers。\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "# 初始pre-trained神經網絡的訓練權重保存在此URL處\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "#\n",
    "# 然後可以將參數加載到模型的骨架中，然後將其轉換為訓練模型。所以現在如果我們想要使用初始化\n",
    "# 因此，您希望知道要為數據輸入數據，並且不想使用內置權重\n",
    "# 初始V3在頂部具有完全連接的層。因此，通過將include_top設置為false，您指定要忽略它並直接進入卷積。\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "\n",
    "# 現在建立我的預訓練模型\n",
    "# 我可以\"for layer in pre_trained_model.layers:\"迭代它的圖層並鎖定它們，\n",
    "# 不會重新訓練(改變否定\"layer.trainable = False\")。\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# 印出整個model \n",
    "pre_trained_model.summary()\n",
    "\n",
    "\n",
    "#要使用的最後一個layer的名稱，將看到底層已經卷積為3乘3。\n",
    "#但想用更多時所以我轉向模型描述找到mixed7，轉成7乘7的多重卷積的輸出。(視情況所需調整，可不必使用此方法)\n",
    "#但是使用這段代碼，我將抓住那一層開始並將其輸出。所以我們將定義我們的新模型，我們稱之為last_ouput。\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72.0
    },
    "outputId": "b826a860-7899-4936-84cd-8fa40edb2fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#所以我們將定義我們的新模型\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "# 我們稱之為last_ouput，但這只是使用API層的另一種方式。\n",
    "# \"taking the output from the inception model's mixed7 layer\"\n",
    "# \"You start by flattening the input,which just happens to be the output from inception.\"\n",
    "x = layers.Flatten()(last_output)\n",
    "\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "# And then add a hidden layer.叫\"Dense\"\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.2\n",
    "# 本周講述的重點工具，在這裡我們dropout 20%的權重\n",
    "x = layers.Dropout(0.2)(x)   \n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "# 然後你的輸出由sigmoid激活的神經元的layer在兩個項目之間進行分類。\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "# 創建模型，並傳遞您剛剛創建的輸入和圖層定義。\n",
    "model = Model( pre_trained_model.input, x) \n",
    "# 然後使用優化器和損失函數以及要收集的度量標準對其進行編譯\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "#再者使用上次的\"ImageDataGenerator\"如下所示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "11f7ffd1-ed7d-42ad-d41c-5b24112c4e9b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-25 23:09:30--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 2607:f8b0:400e:c08::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
      "\n",
      "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   113MB/s    in 0.6s    \n",
      "\n",
      "2019-05-25 23:09:31 (113 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "       -O /tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "# #圖像生成器來增加圖像，然後，和以前一樣，我們可以通過從指定目錄流出並經歷所有增加來從生成器獲取我們的訓練數據。\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "31222764-b249-4b56-b0ed-70e1e271ebcc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1119.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 0.2276 - acc: 0.9310\n",
      " - 20s - loss: 0.5093 - acc: 0.7580 - val_loss: 0.2276 - val_acc: 0.9310\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1835 - acc: 0.9520\n",
      " - 19s - loss: 0.3760 - acc: 0.8355 - val_loss: 0.1835 - val_acc: 0.9520\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.2530 - acc: 0.9430\n",
      " - 19s - loss: 0.3469 - acc: 0.8575 - val_loss: 0.2530 - val_acc: 0.9430\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1865 - acc: 0.9640\n",
      " - 20s - loss: 0.3237 - acc: 0.8605 - val_loss: 0.1865 - val_acc: 0.9640\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.4009 - acc: 0.9380\n",
      " - 19s - loss: 0.3339 - acc: 0.8560 - val_loss: 0.4009 - val_acc: 0.9380\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.2607 - acc: 0.9480\n",
      " - 19s - loss: 0.3054 - acc: 0.8785 - val_loss: 0.2607 - val_acc: 0.9480\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.3115 - acc: 0.9480\n",
      " - 19s - loss: 0.2839 - acc: 0.8805 - val_loss: 0.3115 - val_acc: 0.9480\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.6222 - acc: 0.9210\n",
      " - 20s - loss: 0.2950 - acc: 0.8755 - val_loss: 0.6222 - val_acc: 0.9210\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3655 - acc: 0.9410\n",
      " - 19s - loss: 0.2694 - acc: 0.8850 - val_loss: 0.3655 - val_acc: 0.9410\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.3511 - acc: 0.9480\n",
      " - 18s - loss: 0.2945 - acc: 0.8780 - val_loss: 0.3511 - val_acc: 0.9480\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.2713 - acc: 0.9610\n",
      " - 20s - loss: 0.2911 - acc: 0.8835 - val_loss: 0.2713 - val_acc: 0.9610\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 5s 103ms/step - loss: 0.3556 - acc: 0.9520\n",
      " - 20s - loss: 0.2591 - acc: 0.8925 - val_loss: 0.3556 - val_acc: 0.9520\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.2661 - acc: 0.9560\n",
      " - 18s - loss: 0.2669 - acc: 0.8890 - val_loss: 0.2661 - val_acc: 0.9560\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.3767 - acc: 0.9490\n",
      " - 19s - loss: 0.2704 - acc: 0.8845 - val_loss: 0.3767 - val_acc: 0.9490\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.3990 - acc: 0.9510\n",
      " - 18s - loss: 0.2737 - acc: 0.8975 - val_loss: 0.3990 - val_acc: 0.9510\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 5s 109ms/step - loss: 0.3815 - acc: 0.9510\n",
      " - 19s - loss: 0.2542 - acc: 0.8955 - val_loss: 0.3815 - val_acc: 0.9510\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.3658 - acc: 0.9550\n",
      " - 20s - loss: 0.2705 - acc: 0.8930 - val_loss: 0.3658 - val_acc: 0.9550\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.6739 - acc: 0.9230\n",
      " - 19s - loss: 0.2626 - acc: 0.8995 - val_loss: 0.6739 - val_acc: 0.9230\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.2953 - acc: 0.9650\n",
      " - 19s - loss: 0.2362 - acc: 0.9155 - val_loss: 0.2953 - val_acc: 0.9650\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.3417 - acc: 0.9550\n",
      " - 19s - loss: 0.2704 - acc: 0.8965 - val_loss: 0.3417 - val_acc: 0.9550\n"
     ]
    }
   ],
   "source": [
    "# now we can train as before with model.fit_generator.and going to run it for 100 epochs\n",
    "history = model.fit_generator(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C2Fp6Se9rKuL",
    "colab_type": "code",
    "outputId": "faa2aeb3-1f77-4681-99e8-be0ab06555bb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299.0
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 將其結果印出觀察\n",
    "# 有趣的是，如果你這樣做，那就是你有不同的情況。\n",
    "# 以下是培訓與驗證準確性的圖表。正如您所看到的，雖然它開始很好，但驗證與培訓的分歧非常糟糕。所以，我們如何解決這個問題？下一篇\n",
    "# Another useful tool to explore at this point is the Dropout.(丟掉部分，避免深度學習下稀釋及發散) \n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "d661VCXP86sN",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "sTU9xolMST3q",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Transfer Learning.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
